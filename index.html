<!DOCTYPE html>
<head>
    <meta charset="utf-8" />
    <!-- model viewer -->
    <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.1.1/model-viewer.min.js"></script>
    <title>GeoDream: Disentangling 2D and Geometric Priors for High-Fidelity and Consistent 3D Generation</title>
	<link rel="icon" type="image/x-icon" href="../assets/css/images/favicon.ico">
    <meta content="GeoDream: Disentangling 2D and Geometric Priors for High-Fidelity and Consistent 3D Generation" name="description" />
    <meta content="summary" name="twitter:card" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="static/css/template.css" rel="stylesheet" type="text/css" />
    <link href="static/css/my_style.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({
            google: {
                families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]
            }
        });
    </script>
    <script type="text/javascript">
        ! function (o, c) {
            var n = c.documentElement,
                t = " w-mod-";
            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
        }(window, document);
    </script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script type="text/javascript" src="static/js/zoom.js"></script>
    <script type="text/javascript" src="static/js/video_comparison.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MLDP9MKGC8"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MLDP9MKGC8');
    </script>
</head>

<body>
    <!-- title -->
    <div class="section hero nerf-_v2">
        <div class="container-2 nerf_header_v2 w-container">
            <h1 class="nerf_title_v2">GeoDream:  <br>Disentangling 2D and Geometric Priors for High-Fidelity and Consistent 3D Generation</h1>
            <div class="nerf_subheader_v2">Arxiv 2023</div>
            <div class="nerf_subheader_v2">
                <div>
                    <a href="https://mabaorui.github.io/" target="_blank" class="nerf_authors_v2">Baorui Ma<span
                            class="text-span_nerf"></span></a><sup> 1</sup>,&nbsp;&nbsp;
                    <!-- <a href="https://mabaorui.github.io/" target="_blank" class="nerf_authors_v2">HaoGe Deng<span
                            class="text-span_nerf"></span></a><sup> 1</sup>,&nbsp;&nbsp; -->
                    <a href="https://mabaorui.github.io//" target="_blank" class="nerf_authors_v2">Junsheng Zhou<span
                            class="text-span_nerf"></span></a><sup> 1</sup>,&nbsp;&nbsp;
                    <a href="https://mabaorui.github.io/" target="_blank" class="nerf_authors_v2">YuShen Liu<span
                            class="text-span_nerf"></span></a><sup> 1</sup>
                    <a href="https://mabaorui.github.io/" target="_blank" class="nerf_authors_v2">Tiejun Huang<span
                        class="text-span_nerf"></span></a><sup> 1</sup>
                    <a href="https://mabaorui.github.io/" target="_blank" class="nerf_authors_v2">Xinlong Wang<span
                        class="text-span_nerf"></span></a><sup> 1</sup>
                </div>
                <div>
                    <h1 class="nerf_affiliation_v2"><sup>1 </sup>HKUST</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>2 </sup>Light Illusions</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>3 </sup>South China University of Technology</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>4 </sup>Tencent AI Lab</h1>
                </div>

                <div class="external-link">
                    <a class="btn" href="https://mabaorui.github.io/" role="button" target="_blank">
                        <i class="ai ai-arxiv"></i> Arxiv </a>
                    <a class="btn" href="paper/neet_to_change.pdf" role="button" target="_blank">
                        <i class="fa fa-file-pdf"></i> Paper </a>
                    <a class="btn" href="https://mabaorui.github.io/" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-github"></i> Code </a>
                    <a class="btn btn-large btn-light" href="https://mabaorui.github.io/" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-youtube"></i> Video </a>
                </div>

            </div>
        </div>

    </div>

    <!-- abstarct -->
    <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">
                Text-to-3D generation by distilling pretrained large-scale text-to-image diffusion 
                models has shown great promise but still suffers from inconsistent 3D geometric 
                structures (Janus problems) and severe artifacts. The aforementioned problems mainly 
                stem from 2D diffusion models lacking 3D awareness during the lifting. In this work, 
                we present GeoDream, a novel method that incorporates explicit generalized 3D priors with 
                2D diffusion priors to enhance the capability of obtaining unambiguous 3D consistent 
                geometric structures without sacrificing diversity or fidelity. Specifically, we first 
                utilize a multi-view diffusion model to generate posed images and then construct cost 
                volume from the predicted image, which serves as native <b style="color: rgb(124, 196, 245);">3D geometric priors</b>, 
                ensuring spatial consistency in 3D space. Subsequently, we further propose to harness 
                3D geometric priors to unlock the great potential of 3D awareness in 2D diffusion priors 
                via a disentangled design. Notably, disentangling 2D and 3D priors allows us to refine 
                3D geometric priors further. We justify that the refined 3D geometric priors aid in the 
                3D-aware capability of 2D diffusion priors, which in turn provides superior guidance for 
                the refinement of 3D geometric priors. Our numerical and visual comparisons demonstrate 
                that GeoDream generates more 3D consistent textured meshes with high-resolution realistic 
                renderings (i.e., 1024 $\times$ 1024) and adheres more closely to semantic coherence.
                <br>
                <!-- <img  src="assets/images/overview.png"> -->
            </p>
        </div>
    </div>

    <!-- Videos -->
    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Videos</h2>
        <div class="grid-container-1">
            <video muted autoplay controls loop width="600" height="400" class="center"> 
                <source src="assets/videos/GeoDream_Video_teaser.mp4" type="video/mp4"> 
            </video>
        </div>
    </div>

    <!-- DMTet-based Generated Results -->
    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">DMTet-based Generated Results</h2>
        <div class="grid-container-4">
            <div>
                <p class="myprompt nerf_text">An astronaut riding a horse</p>
                <video class="video" id="1" loop playsinline autoPlay muted
                src="assets/videos/DMTet_low/27_An_astronaut_riding_a_horse.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="1_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">3D stylized game little building</p>
                <video class="video" id="3" loop playsinline autoPlay muted
                src="assets/videos/DMTet_low/7_3D_stylized_game_little_building.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="3_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A delicious creamy lemon cake</p>
                <video class="video" id="2" loop playsinline autoPlay muted
                src="assets/videos/DMTet_low/16_A_delicious_creamy_lemon_cake.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="2_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A dinosaur toy</p>
                <video class="video" id="0" loop playsinline autoPlay muted
                src="assets/videos/DMTet_low/2_A_dinosaur_toy.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="0_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A kangaroo wearing boxing gloves</p>
                <video class="video" id="5" loop playsinline autoPlay muted
                src="assets/videos/DMTet_low/4_A_kangaroo_wearing_boxing_gloves.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="5_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">3D render of an astronaut</p>
                <video class="video" id="7" loop playsinline autoPlay muted
                src="assets/videos/DMTet_low/6_3D_render_of_a_statue_of_an_astronaut.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="7_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A 3D modeling of a lion</p>
                <video class="video" id="6" loop playsinline autoPlay muted
                src="assets/videos/DMTet_low/8_A_3D_modeling_of_a_lion.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="6_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A bald eagle carved out of wood</p>
                <video class="video" id="4" loop playsinline autoPlay muted
                src="assets/videos/DMTet_low/10_A_bald_eagle_carved_out_of_wood.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="4_merge"></canvas>
            </div>
        </div>
        <!-- Todo more res -->
        <div class="grid-container-1">
            <a class="mybtn" href="nerf-based-gallery_0.html" role="button">
             More Results </a>
        </div>
    </div>

    <!-- Exported Meshes -->
    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Exported Meshes</h2>
        <div class="grid-container-4">
            <div>
                <p class="myprompt nerf_text">An astronaut riding a horse</p>
                <model-viewer src="assets/meshes/1.glb" poster="assets/meshes/astronaut.jpg" 
                    style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" 
                    camera-controls touch-action="pan-y">
                </model-viewer>
            </div>
            <div>
                <p class="myprompt nerf_text">An astronaut riding a horse</p>
                <model-viewer src="assets/meshes/astronaut.glb" poster="assets/meshes/astronaut.jpg" 
                    style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" 
                    camera-controls touch-action="pan-y">
                </model-viewer>
            </div>
            <div>
                <p class="myprompt nerf_text">An astronaut riding a horse</p>
                <model-viewer src="assets/meshes/astronaut.glb" poster="assets/meshes/astronaut.jpg" 
                    style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" 
                    camera-controls touch-action="pan-y">
                </model-viewer>
            </div>
            <div>
                <p class="myprompt nerf_text">An astronaut riding a horse</p>
                <model-viewer src="assets/meshes/astronaut.glb" poster="assets/meshes/astronaut.jpg" 
                    style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" 
                    camera-controls touch-action="pan-y">
                </model-viewer>
            </div>
            <div>
                <p class="myprompt nerf_text">An astronaut riding a horse</p>
                <model-viewer src="assets/meshes/astronaut.glb" poster="assets/meshes/astronaut.jpg" 
                    style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" 
                    camera-controls touch-action="pan-y">
                </model-viewer>
            </div>
            <div>
                <p class="myprompt nerf_text">An astronaut riding a horse</p>
                <model-viewer src="assets/meshes/astronaut.glb" poster="assets/meshes/astronaut.jpg" 
                    style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" 
                    camera-controls touch-action="pan-y">
                </model-viewer>
            </div>
            <div>
                <p class="myprompt nerf_text">An astronaut riding a horse</p>
                <model-viewer src="assets/meshes/astronaut.glb" poster="assets/meshes/astronaut.jpg" 
                    style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" 
                    camera-controls touch-action="pan-y">
                </model-viewer>
            </div>
            <div>
                <p class="myprompt nerf_text">An astronaut riding a horse</p>
                <model-viewer src="assets/meshes/astronaut.glb" poster="assets/meshes/astronaut.jpg" 
                    style="width: 100%; height: 300px;" auto-rotate shadow-intensity="1" 
                    camera-controls touch-action="pan-y">
                </model-viewer>
            </div>
        </div>
        <!-- Todo more res -->
        <div class="grid-container-1">
            <a class="mybtn" href="dmtet-based-gallery_0.html" role="button">
            More Results </a>
        </div>
    </div>

    

    <!-- Method Overview -->
    <!-- <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Method Overview</h2>
        <div class="grid-container-1">
            <img src="assets/images/overview_pipelines-1.png">

            <p>Need to moditied!!! We fine-tune the 2D diffusion model (middle) to generate viewpoint-
    conditioned canonical coordinates maps, which are rendered from canonically oriented 3D assets
    (left), thereby aligning the geometric priors in the 2D diffusion. The aligned geometric priors can
    then be seamlessly integrated into existing text-to-3D pipelines to confer 3D consistency (right),
    while retaining their generalizability to obtain high-fidelity and highly varied 3D content.
            </p>
        </div>
    </div> -->

    <!-- BibTeX -->
    <div class="white_section_nerf grey_container w-container">
    <h2 class="grey-heading_nerf">BibTeX</h2>
    <div class="bibtex">
        <pre><code>@article{sweetdreamer,
    author    = {Weiyu Li and Rui Chen and Xuelin Chen and Ping Tan},
    title     = {GeoDream: Disentangling 2D and Geometric Priors for High-Fidelity and Consistent 3D Generation},
    journal   = {arxiv:2310.02596},
    year      = {2023},
    }</code></pre>
    </div>
</div>

</body>
<footer>
    This project page is inspired by <a href="https://github.com/nerfies/nerfies.github.io">Nerfies.</a>, © Weiyu Li. All rights reserved.
</footer>

</html>
